{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file was taken from https://github.com/reinaw1012/pnet-training/\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import os\n",
    "from mtcnn.layer_factory import LayerFactory\n",
    "from mtcnn.network import Network\n",
    "from mtcnn.exceptions import InvalidImage\n",
    "\n",
    "class PNet(Network):\n",
    "    \"\"\"\n",
    "    Network to propose areas with faces.\n",
    "    \"\"\"\n",
    "    def _config(self):\n",
    "        layer_factory = LayerFactory(self)\n",
    "\n",
    "        layer_factory.new_feed(name='data', layer_shape=(None, 12, 12, 3))\n",
    "        layer_factory.new_conv(name='conv1', kernel_size=(3, 3), channels_output=10, stride_size=(1, 1),\n",
    "                            padding='VALID', relu=False)\n",
    "        layer_factory.new_prelu(name='prelu1')\n",
    "        layer_factory.new_max_pool(name='pool1', kernel_size=(2, 2), stride_size=(2, 2))\n",
    "        layer_factory.new_conv(name='conv2', kernel_size=(3, 3), channels_output=16, stride_size=(1, 1),\n",
    "                               padding='VALID', relu=False)\n",
    "        layer_factory.new_prelu(name='prelu2')\n",
    "        layer_factory.new_conv(name='conv3', kernel_size=(3, 3), channels_output=32, stride_size=(1, 1),\n",
    "                               padding='VALID', relu=False)\n",
    "        layer_factory.new_prelu(name='prelu3')\n",
    "        layer_factory.new_conv(name='conv4-1', kernel_size=(1, 1), channels_output=2, stride_size=(1, 1), relu=False)\n",
    "        layer_factory.new_softmax(name='prob1', axis=3)\n",
    "\n",
    "        layer_factory.new_conv(name='conv4-2', kernel_size=(1, 1), channels_output=4, stride_size=(1, 1),\n",
    "                               input_layer_name='prelu3', relu=False)\n",
    "\n",
    "    def _feed(self, image):\n",
    "        print('Running Pnet!')\n",
    "        return self._session.run(['pnet/conv4-2/BiasAdd:0', 'pnet/prob1:0'], feed_dict={'pnet/input:0': image})\n",
    "\n",
    "def read_pos_images():\n",
    "    #Read positive images:\n",
    "    path, __, filenames = next(os.walk(\"./pos_train/\"))\n",
    "    file_count = len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[0.0,1.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    file = open('./coordinates.txt','r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    idx=[1,0,3,2]\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        line = line[1]\n",
    "        line=line[1:-1]\n",
    "        line = line.split(\",\")\n",
    "        #Transpose coordinates\n",
    "        x=0\n",
    "        nline=[]\n",
    "        for i in idx:\n",
    "            nline.append(line[i])\n",
    "            x=x+1\n",
    "        line=[[[float(c) for c in nline]]]\n",
    "        coordinates.append(line)\n",
    "    #Return images, probs, and coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "def read_neg_images():\n",
    "    #Read negative images:\n",
    "    path, __, filenames = next(os.walk(\"./neg_train/\"))\n",
    "    file_count = len(filenames)\n",
    "    images = np.empty([0,12,3])\n",
    "    for i in range(file_count):\n",
    "        j=i+1\n",
    "        img=cv2.imread(f\"{path}{j}.bmp\")\n",
    "        images=np.append(images,img,axis=0)\n",
    "    #Create list of probabilities:\n",
    "    prob=[]\n",
    "    for i in range(file_count):\n",
    "        prob.append([[[1.0,0.0]]])\n",
    "    #Create list of coordinates:\n",
    "    coordinates=[]\n",
    "    for i in range(file_count):\n",
    "        coordinates.append([[[0.0,0.0,0.0,0.0]]])\n",
    "    #Return images, prob, coordinates\n",
    "    return images, prob, coordinates\n",
    "\n",
    "#Read in all images, probabilities, and coordinates\n",
    "pimages, pprob, pcoordinates = read_pos_images()\n",
    "nimages, nprob, ncoordinates = read_neg_images()\n",
    "o_images=np.append(pimages,nimages,axis=0)\n",
    "o_images=np.reshape(o_images,(-1,12,12,3))\n",
    "o_prob=pprob+nprob\n",
    "o_coordinates=pcoordinates+ncoordinates\n",
    "\n",
    "#Shuffle them up using an index\n",
    "idx=np.arange(len(o_prob))\n",
    "np.random.shuffle(idx)\n",
    "images=np.empty_like(o_images)\n",
    "c=0\n",
    "for i in idx:\n",
    "    images[c]=o_images[i]\n",
    "    c=c+1\n",
    "images=(images-127.5)/128.0\n",
    "images = np.transpose(images, (0, 2, 1, 3)) #Transpose images\n",
    "prob=[]\n",
    "for i in idx:\n",
    "    prob.append(o_prob[i])\n",
    "coordinates=[]\n",
    "for i in idx:\n",
    "    coordinates.append(o_coordinates[i])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "        #Initialize training\n",
    "        sess = tf.Session()\n",
    "        train_net=PNet(sess)\n",
    "        bimg=tf.placeholder(tf.float32, shape=(100,12,12,3))\n",
    "        bprob=tf.placeholder(tf.float32, shape=(100,1,1,2))\n",
    "        bprobmask=tf.placeholder(tf.float32, shape=(100,1))\n",
    "        bcoord=tf.placeholder(tf.float32, shape=(100,1,1,4))\n",
    "        loss=tf.reduce_mean(tf.square(bprob-train_net.get_layer('conv4-1')))+bprobmask*0.5*tf.reduce_mean(tf.square(bcoord-train_net.get_layer('conv4-2')))\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train = optimizer.minimize(loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #Test\n",
    "        img=cv2.imread(\"1.bmp\")\n",
    "        img1=(img-127.5)/128.0\n",
    "        img2=np.expand_dims(img1, 0)\n",
    "        print(train_net.feed(img2))\n",
    "        \n",
    "        #Grab a batch of images, probs, and coordinates, and feed into training\n",
    "        for j in range(10):\n",
    "            i=0\n",
    "            f=100\n",
    "            while f<len(prob):\n",
    "                batchimg=images[i:f]\n",
    "                batchprob=prob[i:f]\n",
    "                k=np.array(prob[i:f])\n",
    "                k1=np.reshape(k,(100,2))\n",
    "                k2=k1[:,1]*1.0\n",
    "                k3=np.reshape(k2,(100,1))\n",
    "                batchprobmask=k3\n",
    "                batchcoord=coordinates[i:f]\n",
    "                i=i+100\n",
    "                f=f+100\n",
    "                sess.run(train,feed_dict={'pnet/input:0': batchimg, bprob: batchprob, bcoord: batchcoord,bprobmask:batchprobmask})\n",
    "            print(train_net.feed(img2))\n",
    "\n",
    "        tf.trainable_variables()\n",
    "        wt=np.load('./data/mtcnn_weights.npy')\n",
    "\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv1/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv1']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv1/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv1']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu1/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu1']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu2/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu2']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/prelu3/alpha:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['prelu3']['alpha']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv2/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv2']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv2/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv2']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv3/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv3']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv3/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv3']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-1/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-1']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-1/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-1']['biases']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-2/weights:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-2']['weights']=w1[0]\n",
    "        var1=[v for v in tf.trainable_variables() if v.name == \"pnet/conv4-2/biases:0\"]\n",
    "        w1=sess.run(var1)\n",
    "        wt.all()['PNet']['conv4-2']['biases']=w1[0]\n",
    "        np.save('./data/mtcnn_weights.npy',wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing an image\n",
    "img=cv2.imread(\"1.bmp\")\n",
    "img1=(img-127.5)/128.0\n",
    "img2=np.expand_dims(img1, 0)\n",
    "print(train_net.feed(img2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct coordinates: 1.bmp: [0.25,0,1,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}