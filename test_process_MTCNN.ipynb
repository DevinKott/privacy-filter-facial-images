{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mtcnn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test image\n",
    "file_name = \"./test_images/abba.png\"\n",
    "gaussian_test = \"gaussian_output.png\"\n",
    "pixelated_test = \"pixelated_output.png\"\n",
    "\n",
    "img = cv2.cvtColor( cv2.imread( file_name ), cv2.COLOR_BGR2RGB )\n",
    "g_img = cv2.cvtColor( cv2.imread( gaussian_test ), cv2.COLOR_BGR2RGB )\n",
    "p_img = cv2.cvtColor( cv2.imread( pixelated_test ), cv2.COLOR_BGR2RGB )\n",
    "\n",
    "# Read in the weights for the MTCNN detector\n",
    "detector = mtcnn.MTCNN( './data/mtcnn_weights.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 53 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f763010e670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 4 faces in ./test_images/abba.png.\n"
     ]
    }
   ],
   "source": [
    "# Detect faces in the image\n",
    "faces = detector.detect_faces( img )\n",
    "\n",
    "print( \"Found {0} faces in {1}.\".format( len(faces), file_name ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 faces in gaussian_output.png.\n",
      "Found 0 faces in pixelated_output.png.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to detect faces in the blurred images.\n",
    "\n",
    "blurred_faces_g = detector.detect_faces( g_img )\n",
    "print( \"Found {0} faces in {1}.\".format( len(blurred_faces_g), gaussian_test ) )\n",
    "\n",
    "blurred_faces_p = detector.detect_faces( p_img )\n",
    "print( \"Found {0} faces in {1}.\".format( len(blurred_faces_p), pixelated_test ) )\n",
    "\n",
    "for index in range(len(blurred_faces_g)):\n",
    "    box = blurred_faces_g[index]['box']\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(g_img, (x, y), (x+w, y+h), (0, 255, 0), 2)    \n",
    "cv2.imwrite( \"output_test_gaussian.png\", g_img )\n",
    "\n",
    "for index in range(len(blurred_faces_p)):\n",
    "    box = blurred_faces_p[index]['box']\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(p_img, (x, y), (x+w, y+h), (0, 255, 0), 2)    \n",
    "cv2.imwrite( \"output_test_pixelated.png\", p_img )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong = 4\n",
    "# Medium = 12\n",
    "# Weak = >32\n",
    "pixelateLevel = 4\n",
    "\n",
    "pixelatedHeight, pixelatedWidth = ( pixelateLevel, pixelateLevel )\n",
    "\n",
    "def pixelateROI( region ):\n",
    "    '''\n",
    "        Pixelate a region of an image by downsizing then resizing back to the original.\n",
    "    '''\n",
    "    height, width, _ = region.shape\n",
    "    \n",
    "    # Will resize the region of interest down to 32 x 32, or 12 x 12, etc etc\n",
    "    resized = cv2.resize( region, ( pixelatedWidth, pixelatedHeight ), interpolation = cv2.INTER_LINEAR )\n",
    "    \n",
    "    # Will resize the 32 x 32 ROI back up to the original width and height\n",
    "    return cv2.resize( resized, ( width, height ), interpolation = cv2.INTER_NEAREST )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianROI( region ):\n",
    "    '''\n",
    "        Blur a region of an image by Gaussian blur.\n",
    "    '''\n",
    "    height, width, _ = region.shape\n",
    "    return cv2.GaussianBlur( region, ( 11, 11 ), 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = 5\n",
    "method = 'pixelate'\n",
    "accepted = [ 'pixelate', 'gaussian' ]\n",
    "\n",
    "# Privacy restrict regions of the image that contain faces.\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    \n",
    "    if method in accepted:\n",
    "        # Grab the R.O.I. of the image (the face)\n",
    "        roi = img[ y - edge:y + h + edge, x - edge:x + w + edge ]\n",
    "        modified_roi = None\n",
    "        \n",
    "        # Perform the blurring technique\n",
    "        if method == 'pixelate':\n",
    "            modified_roi = pixelateROI( roi )\n",
    "        elif method == 'gaussian':\n",
    "            modified_roi = gaussianROI( roi )\n",
    "            \n",
    "        # Replace the face with the modified, blurred R.O.I.\n",
    "        img[ y - edge:y + h + edge, x - edge:x + w + edge ] = modified_roi\n",
    "    else:\n",
    "        print( \"Unknown method: {0}\".format(method) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the image with blurred faces\n",
    "\n",
    "# cv2.imshow(\"Faces found\", img)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite( \"output.png\", img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        frame = cv2.resize(frame, (214, 160))\n",
    "\n",
    "        rbgframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detector.detect_faces(rbgframe)\n",
    "\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        rgbframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detector.detect_faces(rgbframe)\n",
    "\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            frame[y-5:y+h+5, x-5:x+w+5] = cv2.GaussianBlur(frame[y-5:y+h+5, x-5:x+w+5], (15, 15), 10)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 faces!\n"
     ]
    }
   ],
   "source": [
    "print(\"Found\", len(faces), \"faces!\")\n",
    "\n",
    "for face in faces:\n",
    "    box = face['box']\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
